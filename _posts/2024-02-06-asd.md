---
title: Lightweight K8s Alternative: K3s
date: 2024-02-06 20:30:00 -500
categories: [homelab,kubernetes]
tags: [kubernetes,cluster,k3s]
---
# K3s Cluster Deployment

## What is K3s ?

K3s is a lightweight, easy-to-install, deploy, and manage version of vanilla Kubernetes (K8s). No, it is not a fork of Kubernetes. K3s is a certified Kubernetes distribution.

Although K3s is a refined version of Kubernetes (the upstream version), it does not change how Kubernetes works at its core.

**Rancher Labs** created K3s and made it lightweight by removing over 3 billion lines of code from the K8s source code. It trimmed most non-CSI storage providers, alpha features, and legacy components that werenâ€™t necessary to implement the Kubernetes API fully.

The reason I'm choosing K3s over K8s is simple. This will be my lab cluster, which will serve only my experimental failures, so lightweight is better.

## Prerequisites

For a minimal cluster, I use 1 master and 3 worker nodes. The naming in K3s is a little different. Master = Server and Worker = Agent, keep in mind.

|Hostname|IP|vCPU|Memory|Disk|OS|
|---|---|---|---|---|---|
|master-node01|192.168.1.130|4|8|50 GB|Ubuntu 22.04 LTS|
|worker-node01|192.168.1.131|4|8|100 GB|Ubuntu 22.04 LTS|
|worker-node02|192.168.1.132|4|8|100 GB|Ubuntu 22.04 LTS|
|worker-node03|192.168.1.133|4|8|100 GB|Ubuntu 22.04 LTS|

You can use cloud init or template image for all the nodes. Of course you can configure them all from scrath.

All the nodes need to be updated, and the NFS package must be installed because later on, we will need it while playing with Longhorn.

Below, you can see commands for Debian-based distros.

~~~terminal
 # stop the software firewall
 systemctl stop ufw
 systemctl disable ufw

 # get updates, install nfs, and apply
 apt update
 apt install nfs-common -y
 apt upgrade -y

 # clean up
 apt autoremove -y
~~~

## Installing K3s Cluster

The easiest way is to use K3s install scripts but you can check their documentation for several different ways. 

While using install scripts, you can state options with --option syntax. With my below example, my command will install K3s with specific "version", as "server" and with "NoSchedule" tagging. I don't want any pod workload on my master node. Here is the offical documentation link, you can play the options if you need more specification [K3s Official Documentation](https://docs.k3s.io/installation/configuration)

~~~bash
curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION="v1.26.12+k3s1" sh -s - server --node-taint 'node-role.kubernetes.io/master=true:NoSchedule'
~~~  

<span style="font-size:0.7em"> Note: I'm using a specific version, but you can skip this option and use the latest version by default. Just don't forget that in a container and Kubernetes world, version dependency is important and sometimes can be problematic. So you may face some problems while deploying several applications on your cluster.</span>

This script will install Traefik as an ingress controller, Flannel as CNI, and SQLite as a key-value database. If you wish to use etcd as an embedded DB, you can use the --cloud-init option. Check the documentation from this link.

You need to export your K3s config file to run the kubectl command from your terminal. Otherwise, you need to declare the whole path to kubectl, which will not be feasible if you think that you will use this command a hundred times, if not millions.

~~~bash
 export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
~~~

If everything goes well, then the below command will show your master (server) node status as ready.

~~~bash
kubectl get nodes
~~~

Then you need to copy your master (server) node token to add agents to your cluster. Just go to the below path and copy out your token ID.

~~~bash
cat /var/lib/rancher/k3s/server/token
~~~

Now you need to SSH to all three servers who will be your workers. By using the below command, you will install the agent role to your worker (agent) nodes. You need to run the same command with related IPs and the same token on each of your servers.

~~~bash
curl -sfL https://get.k3s.io | K3S_TOKEN="MASTER_NODE_TOKEN" K3S_URL="https://MASTER_NODE_IP:6443" K3S_NODE_NAME="THE_NODE_NAME" INSTALL_K3S_VERSION="v1.26.12+k3s1" sh -
~~~

In my environment, the command seems like this :

~~~bash
curl -sfL https://get.k3s.io | K3S_TOKEN="K10631f4f17992bb7d3283318d18bcf75c742f59257d0159cf415bd3dd340c23ebd::server:f29eceec3fdf971bd9935a7eb1d26fc0" K3S_URL="https://192.168.1.130:6443" K3S_NODE_NAME="worker-node01" INSTALL_K3S_VERSION="v1.26.12+k3s1" sh -
~~~

So, your cluster is ready to use. You can check your fresh worker (agent) nodes' status like below. You will see them in "Ready" state if you got no error while executing scripts on each of them.

~~~terminal
root@master-node01:/home/murat# kubectl get nodes
NAME            STATUS   ROLES                  AGE   VERSION
master-node01   Ready    control-plane,master   21d   v1.26.12+k3s1
worker-node04   Ready    <none>                 12d   v1.26.12+k3s1
worker-node01   Ready    <none>                 21d   v1.26.12+k3s1
worker-node02   Ready    <none>                 21d   v1.26.12+k3s1
~~~

## What to do now ?

Finally you get your K3s cluster up and running. Now according to your needs (or just fun) you can install Rancher to manage your cluster via practical GUI and/or deploy Lognhorn to use as a storage cluster for your persistent volumes.

Take care till the next post, if there will any : )
